{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82b156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#db_connection\n",
    "\n",
    "db_connection = mysql.connector.connect(\n",
    "    host=\"68.178.155.255\",           # or IP address\n",
    "    user=\"Anika12\",\n",
    "    password=\"Anika12\",\n",
    "    database=\"categories_lead\"\n",
    ")\n",
    "cursor = db_connection.cursor(dictionary=True)\n",
    "cursor.execute(\"SHOW TABLES;\")\n",
    "for table in cursor:\n",
    "  print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32837d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mysql-connector-python -q\n",
    "import mysql.connector\n",
    "\n",
    "\n",
    "!pip install transformers accelerate -q\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "model_id = \"google/flan-t5-xl\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec54ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def   build_negative_sentiment_flag_prompt(conversation):\n",
    "    return f\"\"\"\n",
    "You are a CRM assistant.\n",
    "\n",
    "Your task is to **analyze this lead conversation** and check if it shows **any sign of negative sentiment**, based on these 3 types:\n",
    "\n",
    "üîπ Complaint ‚Äì about service, delays, lack of follow-up, or experience\n",
    "üîπ Frustration ‚Äì irritated tone, repeated follow-ups, impatience\n",
    "üîπ Negative Product/Service Feedback ‚Äì bugs, crashes, not working, too expensive\n",
    "\n",
    "‚úÖ If **any one** of the above is present in the conversation, return: **True**\n",
    "‚ùå If none are found, return: **False**\n",
    "\n",
    "---\n",
    "\n",
    "Examples:\n",
    "\n",
    "1.\n",
    "sent: Just checking again.\n",
    "received: You guys never reply on time.\n",
    "‚Üí Complaint detected\n",
    "Return: True\n",
    "\n",
    "2.\n",
    "sent: Hi, any update?\n",
    "received: This tool is crashing again.\n",
    "‚Üí Negative Product Feedback detected\n",
    "Return: True\n",
    "\n",
    "3.\n",
    "sent: Hello, following up.\n",
    "received: No one listens!\n",
    "‚Üí Frustration detected\n",
    "Return: True\n",
    "\n",
    "4.\n",
    "sent: Thanks, we‚Äôll get back if needed.\n",
    "received: Okay, noted.\n",
    "‚Üí No negative signal\n",
    "Return: False\n",
    "\n",
    "---\n",
    "\n",
    "Now analyze the conversation below and return only `True` or `False`:\n",
    "\n",
    "{conversation}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08084c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d42cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#updates both inactivity_days and emails_category\n",
    "\n",
    "from datetime import datetime\n",
    "import mysql.connector\n",
    "\n",
    "# =========================\n",
    "# DB CONNECTION\n",
    "# =========================\n",
    "db_connection = mysql.connector.connect(\n",
    "    host=\"68.178.155.255\",\n",
    "    user=\"Anika12\",\n",
    "    password=\"Anika12\",\n",
    "    database=\"categories_lead\"\n",
    ")\n",
    "cursor = db_connection.cursor(dictionary=True)\n",
    "\n",
    "# =========================\n",
    "# MAIN PROCESS\n",
    "# =========================\n",
    "cursor.execute(\"SELECT DISTINCT lead_id FROM emails WHERE lead_id IS NOT NULL\")\n",
    "lead_ids = cursor.fetchall()\n",
    "\n",
    "for row in lead_ids:\n",
    "    lead_id = row['lead_id']\n",
    "\n",
    "    # Get last_contact_date from lead_engagement_summary\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT last_contact_date\n",
    "        FROM lead_engagement_summary\n",
    "        WHERE lead_id = %s\n",
    "    \"\"\", (lead_id,))\n",
    "    contact_row = cursor.fetchone()\n",
    "    last_contact_date = contact_row['last_contact_date'] if contact_row else None\n",
    "\n",
    "    # Step 1: Calculate inactivity_days\n",
    "    inactivity_days = 0\n",
    "    if last_contact_date:\n",
    "        inactivity_days = (datetime.now().date() - last_contact_date).days\n",
    "        print(f\"üìÖ Lead {lead_id} ‚Üí Days since last contact: {inactivity_days}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Lead {lead_id} has no last_contact_date\")\n",
    "\n",
    "    # Step 2: Analyze last 5 emails for sentiment\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT direction, body, timestamp\n",
    "        FROM emails\n",
    "        WHERE lead_id = %s\n",
    "        ORDER BY timestamp DESC\n",
    "        LIMIT 5\n",
    "    \"\"\", (lead_id,))\n",
    "    latest_emails = cursor.fetchall()\n",
    "    email_chain = list(reversed(latest_emails))  # oldest to newest\n",
    "\n",
    "    print(f\"\\n===== LEAD {lead_id} ‚Äî Last 5 Email Pairs Analysis =====\")\n",
    "    negative_count = 0\n",
    "    i = 0\n",
    "    while i < len(email_chain) - 1:\n",
    "        current = email_chain[i]\n",
    "        next_msg = email_chain[i + 1]\n",
    "\n",
    "        if current['direction'].lower() == 'sent' and next_msg['direction'].lower() == 'received':\n",
    "            sent_text = current['body'].strip()\n",
    "            received_text = next_msg['body'].strip()\n",
    "            pair_convo = f\"sent: {sent_text}\\nreceived: {received_text}\"\n",
    "            prompt = build_negative_sentiment_flag_prompt(pair_convo)\n",
    "            output = run_model(prompt)\n",
    "\n",
    "            print(f\"üì® Sent: {sent_text}\")\n",
    "            print(f\"üì® Received: {received_text}\")\n",
    "            print(f\"üß† Model Output: {output}\")\n",
    "\n",
    "            if output.lower() == \"true\":\n",
    "                negative_count += 1\n",
    "                print(\"üî¥ Negative Sentiment Detected!\")\n",
    "                print(\"------------------------------------------------\")\n",
    "\n",
    "            i += 2\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    # Step 3: Update lead_engagement_summary\n",
    "    cursor.execute(\"\"\"\n",
    "        UPDATE lead_engagement_summary\n",
    "        SET emails_category = %s,\n",
    "            inactivity_days = %s\n",
    "        WHERE lead_id = %s\n",
    "    \"\"\", (negative_count, inactivity_days, lead_id))\n",
    "\n",
    "    print(f\"üü° Lead {lead_id} ‚û§ Sentiment Count (emails_category): {negative_count}, Inactivity Days: {inactivity_days}\")\n",
    "\n",
    "# =========================\n",
    "# FINALIZE\n",
    "# =========================\n",
    "db_connection.commit()\n",
    "cursor.close()\n",
    "db_connection.close()\n",
    "print(\"\\n‚úÖ All updates complete in lead_engagement_summary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uodates for calls\n",
    "from datetime import datetime\n",
    "import mysql.connector\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# =========================\n",
    "# MODEL SETUP\n",
    "# =========================\n",
    "model_name = \"google/flan-t5-base\"  # You can change to flan-t5-xl if needed\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "def run_model(prompt):\n",
    "    try:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "        result = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "        return result if result else \"False\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Model error: {e}\")\n",
    "        return \"False\"\n",
    "\n",
    "# =========================\n",
    "# PROMPT FUNCTION\n",
    "# =========================\n",
    "def build_negative_sentiment_flag_prompt_for_calls(latest_call_result_block):\n",
    "    return f\"\"\"\n",
    "You are a CRM assistant.\n",
    "\n",
    "Your task is to **analyze this latest call summary** and check if it shows **any sign of negative sentiment**, based on these 3 types:\n",
    "\n",
    "üîπ Complaint ‚Äì about service, delays, lack of follow-up, or poor experience  \n",
    "üîπ Frustration ‚Äì irritated tone, repeated follow-ups, impatience  \n",
    "üîπ Negative Product/Service Feedback ‚Äì bugs, integration issues, not working, too expensive\n",
    "\n",
    "‚úÖ If **any one** of the above is present in the call summary, return: **True**  \n",
    "‚ùå If none are found, return: **False**\n",
    "\n",
    "---\n",
    "\n",
    "Examples:\n",
    "\n",
    "1.  \n",
    "üìû call_result: \"Pending\"  \n",
    "üìù description: \"Client is annoyed by delays and said no one followed up\"  \n",
    "‚Üí Complaint & Frustration  \n",
    "Return: True\n",
    "\n",
    "2.  \n",
    "üìû call_result: \"Resolved\"  \n",
    "üìù description: \"Client complained about confusing integration options\"  \n",
    "‚Üí Negative Product Feedback  \n",
    "Return: True\n",
    "\n",
    "3.  \n",
    "üìû call_result: \"Negotiation\"  \n",
    "üìù description: \"Lead is pushing for big discounts, unhappy with pricing\"  \n",
    "‚Üí Negative Product Feedback (Price)  \n",
    "Return: True\n",
    "\n",
    "4.  \n",
    "üìû call_result: \"Connected\"  \n",
    "üìù description: \"Client asked some clarifications, no concerns raised\"  \n",
    "‚Üí No negative sentiment  \n",
    "Return: False\n",
    "\n",
    "---\n",
    "\n",
    "Now analyze the call summary below and return only `True` or `False`:\n",
    "\n",
    "üìû call_result: {latest_call_result_block.get('call_result', 'N/A')}  \n",
    "üìù description: {latest_call_result_block.get('description', 'N/A')}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# =========================\n",
    "# DB CONNECTION\n",
    "# =========================\n",
    "db_connection = mysql.connector.connect(\n",
    "    host=\"68.178.155.255\",\n",
    "    user=\"Anika12\",\n",
    "    password=\"Anika12\",\n",
    "    database=\"categories_lead\"\n",
    ")\n",
    "cursor = db_connection.cursor(dictionary=True)\n",
    "\n",
    "# =========================\n",
    "# MAIN LOGIC: CALL SENTIMENT\n",
    "# =========================\n",
    "cursor.execute(\"SELECT DISTINCT lead_id FROM calls WHERE lead_id IS NOT NULL\")\n",
    "lead_ids = cursor.fetchall()\n",
    "\n",
    "for row in lead_ids:\n",
    "    lead_id = row['lead_id']\n",
    "\n",
    "    # Fetch latest call per lead by combining call_date + call_time\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT call_result, description\n",
    "        FROM calls\n",
    "        WHERE lead_id = %s\n",
    "        ORDER BY STR_TO_DATE(CONCAT(call_date, ' ', call_time), '%%Y-%%m-%%d %%h:%%i %%p') DESC\n",
    "        LIMIT 1\n",
    "    \"\"\", (lead_id,))\n",
    "    latest_call = cursor.fetchone()\n",
    "\n",
    "    if latest_call:\n",
    "        prompt = build_negative_sentiment_flag_prompt_for_calls(latest_call)\n",
    "        output = run_model(prompt)\n",
    "\n",
    "        print(f\"‚òéÔ∏è Lead {lead_id}\")\n",
    "        print(f\"üìû call_result: {latest_call['call_result']}\")\n",
    "        print(f\"üìù description: {latest_call['description']}\")\n",
    "        print(f\"üß† Model Output: {output}\")\n",
    "\n",
    "        # Update calls_category (1 for True, 0 for False)\n",
    "        cursor.execute(\"\"\"\n",
    "            UPDATE lead_engagement_summary\n",
    "            SET calls_category = %s\n",
    "            WHERE lead_id = %s\n",
    "        \"\"\", (1 if output.lower() == \"true\" else 0, lead_id))\n",
    "\n",
    "        print(f\"‚úÖ Updated calls_category for lead {lead_id} ‚Üí {output}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No call found for lead {lead_id}\")\n",
    "\n",
    "# =========================\n",
    "# FINALIZE\n",
    "# =========================\n",
    "db_connection.commit()\n",
    "cursor.close()\n",
    "db_connection.close()\n",
    "print(\"\\n‚úÖ All call-based sentiment updates complete in lead_engagement_summary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce16fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meetings\n",
    "from datetime import datetime\n",
    "import mysql.connector\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# =========================\n",
    "# MODEL SETUP\n",
    "# =========================\n",
    "model_name = \"google/flan-t5-base\"  # or flan-t5-xl if you prefer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "def run_model(prompt):\n",
    "    try:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "        result = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "        return result if result else \"False\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Model error: {e}\")\n",
    "        return \"False\"\n",
    "\n",
    "# =========================\n",
    "# PROMPT FUNCTION\n",
    "# =========================\n",
    "def build_negative_sentiment_flag_prompt_for_meetings(latest_meeting_description):\n",
    "    return f\"\"\"\n",
    "You are a CRM assistant.\n",
    "\n",
    "Your task is to **analyze this meeting description** and check if it shows **any sign of negative sentiment**, based on these 3 types:\n",
    "\n",
    "üîπ Complaint ‚Äì about service, delays, lack of follow-up, or poor experience  \n",
    "üîπ Frustration ‚Äì irritated tone, repeated follow-ups, impatience  \n",
    "üîπ Negative Product/Service Feedback ‚Äì bugs, integration issues, not working, too expensive\n",
    "\n",
    "‚úÖ If **any one** of the above is present in the meeting description, return: **True**  \n",
    "‚ùå If none are found, return: **False**\n",
    "\n",
    "---\n",
    "\n",
    "Examples:\n",
    "\n",
    "1.  \n",
    "üìù description: \"Client expressed frustration that no one joined the demo as planned.\"  \n",
    "‚Üí Complaint + Frustration  \n",
    "Return: True\n",
    "\n",
    "2.  \n",
    "üìù description: \"Lead mentioned the CRM setup has several bugs and delays.\"  \n",
    "‚Üí Negative Product Feedback  \n",
    "Return: True\n",
    "\n",
    "3.  \n",
    "üìù description: \"Demo went well, no concerns raised.\"  \n",
    "‚Üí No negative signal  \n",
    "Return: False\n",
    "\n",
    "4.  \n",
    "üìù description: \"Client was impatient and said the onboarding is taking too long.\"  \n",
    "‚Üí Complaint + Frustration  \n",
    "Return: True\n",
    "\n",
    "---\n",
    "\n",
    "Now analyze the meeting description below and return only `True` or `False`:\n",
    "\n",
    "üìù description: {latest_meeting_description}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# =========================\n",
    "# DB CONNECTION\n",
    "# =========================\n",
    "db_connection = mysql.connector.connect(\n",
    "    host=\"68.178.155.255\",\n",
    "    user=\"Anika12\",\n",
    "    password=\"Anika12\",\n",
    "    database=\"categories_lead\"\n",
    ")\n",
    "cursor = db_connection.cursor(dictionary=True)\n",
    "\n",
    "# =========================\n",
    "# MAIN LOGIC: MEETING SENTIMENT\n",
    "# =========================\n",
    "cursor.execute(\"SELECT DISTINCT related_to as lead_id FROM meetings WHERE related_to IS NOT NULL\")\n",
    "lead_ids = cursor.fetchall()\n",
    "\n",
    "for row in lead_ids:\n",
    "    lead_id = row['lead_id']\n",
    "\n",
    "    # Fetch latest meeting based on meeting_datetime\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT description\n",
    "        FROM meetings\n",
    "        WHERE related_to = %s\n",
    "        ORDER BY STR_TO_DATE(meeting_datetime, '%%Y-%%m-%%dT%%H:%%i') DESC\n",
    "        LIMIT 1\n",
    "    \"\"\", (lead_id,))\n",
    "    latest_meeting = cursor.fetchone()\n",
    "\n",
    "    if latest_meeting and latest_meeting['description']:\n",
    "        prompt = build_negative_sentiment_flag_prompt_for_meetings(latest_meeting['description'])\n",
    "        output = run_model(prompt)\n",
    "\n",
    "        print(f\"üìÖ Lead {lead_id}\")\n",
    "        print(f\"üìù description: {latest_meeting['description']}\")\n",
    "        print(f\"üß† Model Output: {output}\")\n",
    "\n",
    "        # Update meetings_category in lead_engagement_summary\n",
    "        cursor.execute(\"\"\"\n",
    "            UPDATE lead_engagement_summary\n",
    "            SET meetings_category = %s\n",
    "            WHERE lead_id = %s\n",
    "        \"\"\", (1 if output.lower() == \"true\" else 0, lead_id))\n",
    "\n",
    "        print(f\"‚úÖ Updated meetings_category for lead {lead_id} ‚Üí {output}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No valid meeting found for lead {lead_id}\")\n",
    "\n",
    "# =========================\n",
    "# FINALIZE\n",
    "# =========================\n",
    "db_connection.commit()\n",
    "cursor.close()\n",
    "db_connection.close()\n",
    "print(\"\\n‚úÖ All meeting-based sentiment updates complete in lead_engagement_summary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a5dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inactivity_days, emails_catgeory,calls_catgeory,meetings_category \n",
    "\n",
    "from datetime import datetime\n",
    "import mysql.connector\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# =========================\n",
    "# MODEL SETUP\n",
    "# =========================\n",
    "model_name = \"google/flan-t5-base\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "def run_model(prompt):\n",
    "    try:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "        result = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "        return result if result else \"False\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Model error: {e}\")\n",
    "        return \"False\"\n",
    "\n",
    "# =========================\n",
    "# PROMPT FUNCTIONS\n",
    "# =========================\n",
    "def build_email_prompt(convo):\n",
    "    return f\"\"\"\n",
    "You are a CRM assistant.\n",
    "\n",
    "Your task is to **analyze this lead conversation** and check if it shows **any sign of negative sentiment**, based on these 3 types:\n",
    "\n",
    "üîπ Complaint ‚Äì about service, delays, lack of follow-up, or experience  \n",
    "üîπ Frustration ‚Äì irritated tone, repeated follow-ups, impatience  \n",
    "üîπ Negative Product/Service Feedback ‚Äì bugs, crashes, not working, too expensive\n",
    "\n",
    "‚úÖ If **any one** of the above is present in the conversation, return: **True**  \n",
    "‚ùå If none are found, return: **False**\n",
    "\n",
    "---\n",
    "{convo}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "def build_call_prompt(call):\n",
    "    return f\"\"\"\n",
    "You are a CRM assistant.\n",
    "\n",
    "Your task is to **analyze this latest call summary** and check if it shows **any sign of negative sentiment**, based on these 3 types:\n",
    "\n",
    "üîπ Complaint ‚Äì about service, delays, lack of follow-up, or poor experience  \n",
    "üîπ Frustration ‚Äì irritated tone, repeated follow-ups, impatience  \n",
    "üîπ Negative Product/Service Feedback ‚Äì bugs, integration issues, not working, too expensive\n",
    "\n",
    "‚úÖ If **any one** of the above is present in the call summary, return: **True**  \n",
    "‚ùå If none are found, return: **False**\n",
    "\n",
    "---\n",
    "üìû call_result: {call.get('call_result', 'N/A')}  \n",
    "üìù description: {call.get('description', 'N/A')}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "def build_meeting_prompt(description):\n",
    "    return f\"\"\"\n",
    "You are a CRM assistant.\n",
    "\n",
    "Your task is to **analyze this meeting description** and check if it shows **any sign of negative sentiment**, based on these 3 types:\n",
    "\n",
    "üîπ Complaint ‚Äì about service, delays, lack of follow-up, or poor experience  \n",
    "üîπ Frustration ‚Äì irritated tone, repeated follow-ups, impatience  \n",
    "üîπ Negative Product/Service Feedback ‚Äì bugs, integration issues, not working, too expensive\n",
    "\n",
    "‚úÖ If **any one** of the above is present in the meeting description, return: **True**  \n",
    "‚ùå If none are found, return: **False**\n",
    "\n",
    "---\n",
    "üìù description: {description}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# =========================\n",
    "# DB CONNECTION\n",
    "# =========================\n",
    "db = mysql.connector.connect(\n",
    "    host=\"68.178.155.255\",\n",
    "    user=\"Anika12\",\n",
    "    password=\"Anika12\",\n",
    "    database=\"categories_lead\"\n",
    ")\n",
    "cursor = db.cursor(dictionary=True)\n",
    "\n",
    "# =========================\n",
    "# GET DISTINCT LEADS\n",
    "# =========================\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT DISTINCT lead_id FROM (\n",
    "        SELECT lead_id FROM emails\n",
    "        UNION\n",
    "        SELECT lead_id FROM calls\n",
    "        UNION\n",
    "        SELECT related_to AS lead_id FROM meetings\n",
    "    ) AS all_leads\n",
    "\"\"\")\n",
    "leads = cursor.fetchall()\n",
    "\n",
    "# =========================\n",
    "# PROCESS EACH LEAD\n",
    "# =========================\n",
    "for lead in leads:\n",
    "    lead_id = lead['lead_id']\n",
    "    print(f\"\\nüîÑ Processing lead: {lead_id}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # EMAILS: sentiment + date\n",
    "    # -------------------------\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT direction, body, timestamp\n",
    "        FROM emails\n",
    "        WHERE lead_id = %s\n",
    "        ORDER BY timestamp DESC\n",
    "        LIMIT 5\n",
    "    \"\"\", (lead_id,))\n",
    "    emails = list(reversed(cursor.fetchall()))\n",
    "    email_neg_count = 0\n",
    "    latest_email_time = None\n",
    "    i = 0\n",
    "    while i < len(emails) - 1:\n",
    "        sent = emails[i]\n",
    "        received = emails[i + 1]\n",
    "        if sent['direction'] == 'sent' and received['direction'] == 'received':\n",
    "            convo = f\"sent: {sent['body'].strip()}\\nreceived: {received['body'].strip()}\"\n",
    "            prompt = build_email_prompt(convo)\n",
    "            output = run_model(prompt)\n",
    "            if output.lower() == 'true':\n",
    "                email_neg_count += 1\n",
    "            i += 2\n",
    "        else:\n",
    "            i += 1\n",
    "    if emails:\n",
    "        latest_email_time = max(e['timestamp'] for e in emails if e['timestamp'])\n",
    "\n",
    "    # -------------------------\n",
    "    # CALLS: sentiment + date\n",
    "    # -------------------------\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT call_result, description, call_date\n",
    "        FROM calls\n",
    "        WHERE lead_id = %s\n",
    "        ORDER BY STR_TO_DATE(call_date, '%%Y-%%m-%%d') DESC\n",
    "        LIMIT 1\n",
    "    \"\"\", (lead_id,))\n",
    "    call = cursor.fetchone()\n",
    "    calls_category = 0\n",
    "    latest_call_time = None\n",
    "    if call:\n",
    "        prompt = build_call_prompt(call)\n",
    "        output = run_model(prompt)\n",
    "        if output.lower() == \"true\":\n",
    "            calls_category = 1\n",
    "        if call['call_date']:\n",
    "            latest_call_time = datetime.strptime(call['call_date'], \"%Y-%m-%d\")\n",
    "\n",
    "    # -------------------------\n",
    "    # MEETINGS: sentiment + date\n",
    "    # -------------------------\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT description, meeting_datetime\n",
    "        FROM meetings\n",
    "        WHERE related_to = %s\n",
    "        ORDER BY STR_TO_DATE(meeting_datetime, '%%Y-%%m-%%dT%%H:%%i') DESC\n",
    "        LIMIT 1\n",
    "    \"\"\", (lead_id,))\n",
    "    meeting = cursor.fetchone()\n",
    "    meetings_category = 0\n",
    "    latest_meeting_time = None\n",
    "    if meeting and meeting['description']:\n",
    "        prompt = build_meeting_prompt(meeting['description'])\n",
    "        output = run_model(prompt)\n",
    "        if output.lower() == \"true\":\n",
    "            meetings_category = 1\n",
    "        if meeting['meeting_datetime']:\n",
    "            latest_meeting_time = datetime.strptime(meeting['meeting_datetime'], \"%Y-%m-%dT%H:%M\")\n",
    "\n",
    "    # -------------------------\n",
    "    # CALCULATE INACTIVITY DAYS\n",
    "    # -------------------------\n",
    "    latest_dates = [d for d in [latest_email_time, latest_call_time, latest_meeting_time] if d]\n",
    "    inactivity_days = (datetime.now() - max(latest_dates)).days if latest_dates else None\n",
    "\n",
    "    # -------------------------\n",
    "    # UPDATE SUMMARY TABLE\n",
    "    # -------------------------\n",
    "    cursor.execute(\"\"\"\n",
    "        UPDATE lead_engagement_summary\n",
    "        SET inactivity_days = %s,\n",
    "            emails_category = %s,\n",
    "            calls_category = %s,\n",
    "            meetings_category = %s\n",
    "        WHERE lead_id = %s\n",
    "    \"\"\", (\n",
    "        inactivity_days,\n",
    "        email_neg_count,\n",
    "        calls_category,\n",
    "        meetings_category,\n",
    "        lead_id\n",
    "    ))\n",
    "\n",
    "    print(f\"üìä Updated ‚û§ inactivity_days: {inactivity_days}, emails: {email_neg_count}, calls: {calls_category}, meetings: {meetings_category}\")\n",
    "\n",
    "# =========================\n",
    "# COMMIT & CLOSE\n",
    "# =========================\n",
    "db.commit()\n",
    "cursor.close()\n",
    "db.close()\n",
    "print(\"\\n‚úÖ All updates complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e225afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total interactions week wise\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# ---------------------------\n",
    "# Database Connection\n",
    "# ---------------------------\n",
    "def connect_db():\n",
    "    return mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"\",\n",
    "        database=\"categories_lead\"\n",
    "    )\n",
    "\n",
    "# ---------------------------\n",
    "# Utility: Week Binning\n",
    "# ---------------------------\n",
    "def bin_weekly(entries, start_date):\n",
    "    weekly_counts = {}\n",
    "    for time in entries:\n",
    "        delta = (time - start_date).days\n",
    "        week_num = max((delta // 7) + 1, 1)\n",
    "        key = f\"week {week_num}\"\n",
    "        weekly_counts[key] = weekly_counts.get(key, 0) + 1\n",
    "    return weekly_counts\n",
    "\n",
    "def fill_missing_weeks(*dicts):\n",
    "    max_week = 0\n",
    "    for d in dicts:\n",
    "        if d:\n",
    "            max_week = max(max_week, max(int(k.split()[1]) for k in d))\n",
    "    filled = {}\n",
    "    for i in range(1, max_week + 1):\n",
    "        filled[f\"week {i}\"] = 0\n",
    "    for d in dicts:\n",
    "        for k, v in d.items():\n",
    "            filled[k] += v\n",
    "    return dict(sorted(filled.items(), key=lambda x: int(x[0].split()[1])))\n",
    "\n",
    "# ---------------------------\n",
    "# Main Logic\n",
    "# ---------------------------\n",
    "def calculate_total_interactions():\n",
    "    db = connect_db()\n",
    "    cursor = db.cursor(dictionary=True)\n",
    "\n",
    "    # Fetch all leads and their created_at\n",
    "    cursor.execute(\"SELECT lead_id, created_at FROM leads\")\n",
    "    leads = cursor.fetchall()\n",
    "\n",
    "    for lead in leads:\n",
    "        lead_id = lead['lead_id']\n",
    "        created_at = lead['created_at']\n",
    "        if isinstance(created_at, str):\n",
    "            created_at = datetime.strptime(created_at, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        # Get email timestamps\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT timestamp FROM emails\n",
    "            WHERE lead_id = %s AND timestamp IS NOT NULL\n",
    "        \"\"\", (lead_id,))\n",
    "        email_entries = [\n",
    "            datetime.strptime(row['timestamp'], \"%Y-%m-%d %H:%M:%S\")\n",
    "            for row in cursor.fetchall()\n",
    "        ]\n",
    "        email_weeks = bin_weekly(email_entries, created_at)\n",
    "\n",
    "        # Get call timestamps\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT created_at FROM calls\n",
    "            WHERE lead_id = %s AND created_at IS NOT NULL\n",
    "        \"\"\", (lead_id,))\n",
    "        call_entries = [row['created_at'] for row in cursor.fetchall()]\n",
    "        call_weeks = bin_weekly(call_entries, created_at)\n",
    "\n",
    "        # Get meeting timestamps\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT created_at FROM meetings\n",
    "            WHERE related_to = %s AND created_at IS NOT NULL\n",
    "        \"\"\", (lead_id,))\n",
    "        meeting_entries = [row['created_at'] for row in cursor.fetchall()]\n",
    "        meeting_weeks = bin_weekly(meeting_entries, created_at)\n",
    "\n",
    "        # Combine all into total_interactions\n",
    "        total_weeks = fill_missing_weeks(email_weeks, call_weeks, meeting_weeks)\n",
    "        total_json = json.dumps(total_weeks)\n",
    "\n",
    "        # Update lead_engagement_summary\n",
    "        cursor.execute(\"\"\"\n",
    "            UPDATE lead_engagement_summary\n",
    "            SET total_interactions = %s\n",
    "            WHERE lead_id = %s\n",
    "        \"\"\", (total_json, lead_id))\n",
    "\n",
    "        print(f\"‚úÖ Lead {lead_id} ‚Üí {total_json}\")\n",
    "\n",
    "    db.commit()\n",
    "    db.close()\n",
    "\n",
    "# ---------------------------\n",
    "# Run it\n",
    "# ---------------------------\n",
    "calculate_total_interactions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb97900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logic to predict churn or not\n",
    "import json\n",
    "import mysql.connector\n",
    "\n",
    "def connect_to_db():\n",
    "    return mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"\",\n",
    "        database=\"categories_lead\"\n",
    "    )\n",
    "\n",
    "def fetch_all_leads():\n",
    "    try:\n",
    "        conn = connect_to_db()\n",
    "        cursor = conn.cursor(dictionary=True)\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT lead_id, inactivity_days, negative_sentiment_count, total_interactions\n",
    "            FROM lead_engagement_summary\n",
    "        \"\"\")\n",
    "        results = cursor.fetchall()\n",
    "        conn.close()\n",
    "        return results\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error: {err}\")\n",
    "        return []\n",
    "\n",
    "def update_churn_label(lead_id, churn_score, churn_label):\n",
    "    try:\n",
    "        conn = connect_to_db()\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"\"\"\n",
    "            UPDATE lead_engagement_summary\n",
    "            SET churn_score = %s,\n",
    "                churn_label = %s\n",
    "            WHERE lead_id = %s\n",
    "        \"\"\", (churn_score, churn_label, lead_id))\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error updating lead {lead_id}: {err}\")\n",
    "\n",
    "def calculate_churn_score(lead):\n",
    "    score = 0\n",
    "\n",
    "    # 1. Negative Sentiment Count (Max 30)\n",
    "    nsc = lead.get('negative_sentiment_count') or 0\n",
    "    if nsc == 1:\n",
    "        score += 10\n",
    "    elif nsc == 2:\n",
    "        score += 20\n",
    "    elif nsc >= 3:\n",
    "        score += 30\n",
    "\n",
    "    # 2. Inactivity Days (Max 35)\n",
    "    try:\n",
    "        inactivity = int(lead.get('inactivity_days') or 0)\n",
    "    except:\n",
    "        inactivity = 0\n",
    "\n",
    "    if inactivity >= 30:\n",
    "        score += 35\n",
    "    else:\n",
    "        score += (inactivity / 30) * 35\n",
    "\n",
    "    # 3. Total Interactions Week 4+ (Max 35)\n",
    "    total_json = lead.get('total_interactions') or '{}'\n",
    "    bad_weight = 0\n",
    "    total_weight = 0\n",
    "    try:\n",
    "        interaction_dict = json.loads(total_json)\n",
    "        for week_key, count in interaction_dict.items():\n",
    "            if week_key.startswith(\"week\"):\n",
    "                week_num = int(week_key.split()[1])\n",
    "                if week_num >= 4:\n",
    "                    weight = week_num - 3\n",
    "                    total_weight += weight\n",
    "                    if count <= 2:\n",
    "                        bad_weight += weight\n",
    "    except Exception as e:\n",
    "        print(f\"Error decoding total_interactions for lead {lead['lead_id']}: {e}\")\n",
    "\n",
    "    if total_weight > 0:\n",
    "        score += (bad_weight / total_weight) * 35\n",
    "\n",
    "    # Cap score\n",
    "    score = round(min(score, 100), 2)\n",
    "\n",
    "    # Label\n",
    "    if score > 70:\n",
    "        label = \"High Churn Risk\"\n",
    "    elif score >= 40:\n",
    "        label = \"Medium Churn Risk\"\n",
    "    else:\n",
    "        label = \"Low Churn Risk\"\n",
    "\n",
    "    return score, label\n",
    "\n",
    "# üöÄ Execute for all leads\n",
    "leads = fetch_all_leads()\n",
    "\n",
    "for lead in leads:\n",
    "    score, label = calculate_churn_score(lead)\n",
    "    update_churn_label(lead['lead_id'], score, label)\n",
    "    print(f\"Lead {lead['lead_id']} ‚Üí Score: {score}, Label: {label}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
